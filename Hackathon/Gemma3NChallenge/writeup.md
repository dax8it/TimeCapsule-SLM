Project Write-up: TimeCapsuleSLM
The Problem and Our Vision
In an era of information overload, researchers, students, and educators face a common set of challenges: fragmented information, inefficient learning methods, and a lack of privacy-first AI tools. Traditional learning is often linear and lacks the personalization needed for individual students, while teachers are burdened with manual content creation and lesson planning. Furthermore, in low-resource environments with limited internet access and hardware, these challenges are magnified, creating a significant barrier to quality education.
Our vision is to empower individuals and communities with a powerful, accessible, and private AI platform. TimeCapsuleSLM is a comprehensive, open-source platform that combines AI-powered research and adaptive learning tools into a single, cohesive experience. By leveraging the on-device, completely offline capabilities of Gemma 3n, we're not just creating another AI tool; we are building a solution that can create meaningful, positive change, especially in underserved educational settings.

How We Use Gemma 3n
TimeCapsuleSLM is built from the ground up to utilize the unique capabilities of Google's Gemma 3n model, making it a powerful, privacy-first, and entirely offline solution.
On-Device Performance and Privacy
At the core of our platform is the ability to run powerful AI models locally. By integrating with Ollama, we can serve Gemma 3n directly on a user's device (laptops, tablets, etc.). This is a critical feature that aligns perfectly with Gemma 3n's design philosophy of on-device, private AI. All data processing for research, document indexing, and learning assistance happens locally, ensuring user data never leaves their device. This is a non-negotiable feature for students and researchers handling sensitive information.
Gemma 3n's Mix'n'Match for Optimized Performance
We leverage Gemma 3n's innovative "mix'n'match" capability to dynamically trade off performance and quality on the fly, tailoring the model's footprint to the user's device capabilities and specific task needs. This is achieved through the custom-developed Timecapsule2.7B-g3n-mix-match model that we have created and published on Hugging Face: https://huggingface.co/bubblspace/Timecapsule2.7B-g3n-mix-match. This allows us to optimize the model's memory footprint and processing speed, making it highly efficient even on resource-constrained devices.
AI-Frames: A Modern Approach to Engaging Learning
TimeCapsuleSLM introduces AI-Frames, a groundbreaking feature that promises a modern and highly engaging way of consuming content. Leveraging Gemma 3n's multimodal understanding, particularly for advanced PDF parsing, AI-Frames transforms traditional linear learning into an interactive, graphical learning experience.
Instead of passively reading or watching, users can interact with interconnected "frames" that combine video segments, parsed document content, and AI-powered assistance. This enables:
Personalized Learning Paths: Both educators and students can create and navigate their own unique learning journeys. Educators can design adaptive curricula, while students can explore topics at their own pace and according to their individual learning styles.
Enhanced Engagement: AI-Frames breaks down complex subjects into digestible, interactive modules, fostering deeper understanding and retention. The visual and interactive nature makes learning more dynamic and less monotonous.
Contextual Assistance: As users move through their personalized paths, Gemma 3n provides real-time, contextual help and concept explanations directly from the parsed documents, ensuring immediate clarification without needing external resources or an internet connection.
This feature is designed to revolutionize how content is consumed, making learning more intuitive, adaptable, and profoundly more engaging for everyone.
Enhancing Education in Low-Resource Environments
Our project directly tackles the challenges of low-resource environments by capitalizing on Gemma 3n's offline-ready and low-power nature.
Offline-First Learning: The local AI processing means students and teachers in areas with poor or no internet connectivity can still access the full power of TimeCapsuleSLM. They can use premade TimeCapsules—our portable, self-contained learning sessions—to continue their education independently.
Minimal Hardware Requirements: Gemma 3n’s efficient architecture, which gives it the memory footprint of a much smaller model, allows TimeCapsuleSLM to run effectively on basic computers and tablets. This makes advanced educational technology accessible to a broader audience, reducing the need for expensive infrastructure.
Dynamic Lesson Planning: For teachers, our platform uses Gemma 3n's advanced reasoning to create dynamic lesson plans that an AI can adapt in real-time based on student performance. This drastically reduces a teacher's workload and allows them to focus on personalized instruction.

Technical Architecture
TimeCapsuleSLM is built on a modern, robust technology stack designed for performance and flexibility.

Local Database and In-Browser RAG: We use RxDB to manage all local data, from research notes to processed documents. This is where our in-browser RAG (Retrieval-Augmented Generation) system shines. All document content is processed, indexed, and stored directly within the user's IndexDB. This approach is exceptionally fast, highly efficient, and paramount for privacy, as all data remains on the user's device. Our semantic search capabilities, powered by Gemma 3n, allow users to find information using natural language queries, directly within their local knowledge base, without sending any data to the cloud.
AI Integration: We use Ollama as our primary interface for local LLM inference. This allows us to easily integrate Gemma 3n and other local models, giving users the freedom to choose their preferred AI backend. There are no cloud-based AI providers integrated; the entire AI ecosystem runs locally.
Frontend: Built with Next.js 15, React 19, and TypeScript, our user interface is both responsive and intuitive. This ensures a seamless user experience across various devices.
Our modular architecture facilitates a multi-agent AI system where different AI agents collaborate seamlessly. These agents are specialized for tasks such as efficient data extraction from parsed documents, intelligent summarization, and synthesizing information to provide the best possible output for research and learning queries. This intelligent orchestration between agents ensures comprehensive analysis and highly relevant responses, all while maintaining context across sessions and adapting to user needs.

The Impact: A New Paradigm for Learning
TimeCapsuleSLM represents a significant step towards democratizing education and research. By using Gemma 3n to bring powerful AI capabilities on-device and entirely offline, we've created a platform that empowers both teachers and students.
Our DeepResearch TimeCapsule system allows researchers to save, share, and collaborate on entire research sessions, preserving the full context of their work. Meanwhile, the AI-Frames system transforms passive content like PDFs and videos into interactive, adaptive learning journeys, with AI assistance derived from local document parsing.
Most importantly, our solution provides a cost-effective, private, and accessible platform for teachers and students in low-resource environments. The ability to prepare and share rich, multimedia-based learning materials—complete with AI assistance—without a constant internet connection, is a game-changer. We are enabling a future where quality education is not limited by location, connectivity, or access to expensive hardware.

